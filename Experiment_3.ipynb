{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUO8lxqyfcpODJLTAdOc05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mayank1525/GENAI/blob/main/Experiment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 3: You are a part of DS team responsible for enhancing search personality of the job portal. Your task is to analyze how stemming can help normalize textual data and compare the behaviour of different stemming techniques."
      ],
      "metadata": {
        "id": "8jyU6YSJaJYX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v9CU3RrHMc6X"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttv04wXQULA5",
        "outputId": "d893912f-0e28-4a1e-c316-2b655920c51c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_descriptions = [\n",
        "    \"We are developing scalable software systems\",\n",
        "    \"The developer is responsible for application development\",\n",
        "    \"Experience in developing backend services is required\"\n",
        "]\n",
        "\n",
        "user_queries = [\n",
        "    \"develop software\",\n",
        "    \"backend developer\",\n",
        "    \"application development\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "TK1QgZKhaG0H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
        "    return tokens\n",
        "def apply_stemming(tokens):\n",
        "    porter = PorterStemmer()\n",
        "    snowball = SnowballStemmer(\"english\")\n",
        "    lancaster = LancasterStemmer()\n",
        "\n",
        "    stems = {\n",
        "        \"Porter\": [porter.stem(word) for word in tokens],\n",
        "        \"Snowball\": [snowball.stem(word) for word in tokens],\n",
        "        \"Lancaster\": [lancaster.stem(word) for word in tokens]\n",
        "    }\n",
        "    return stems\n",
        "\n"
      ],
      "metadata": {
        "id": "C2MJjBJzbqZA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Job Descriptions Stemming \\n\")\n",
        "\n",
        "for jd in job_descriptions:\n",
        "    tokens = preprocess_text(jd)\n",
        "    stems = apply_stemming(tokens)\n",
        "\n",
        "    print(\"Original:\", jd)\n",
        "    print(\"Tokens:\", tokens)\n",
        "    print(\"Porter:\", stems[\"Porter\"])\n",
        "    print(\"Snowball:\", stems[\"Snowball\"])\n",
        "    print(\"Lancaster:\", stems[\"Lancaster\"])\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBy7Lei7cBJt",
        "outputId": "148ea81f-21f4-4f69-dd07-114a930eab24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Descriptions Stemming \n",
            "\n",
            "Original: We are developing scalable software systems\n",
            "Tokens: ['developing', 'scalable', 'software', 'systems']\n",
            "Porter: ['develop', 'scalabl', 'softwar', 'system']\n",
            "Snowball: ['develop', 'scalabl', 'softwar', 'system']\n",
            "Lancaster: ['develop', 'scal', 'softw', 'system']\n",
            "--------------------------------------------------\n",
            "Original: The developer is responsible for application development\n",
            "Tokens: ['developer', 'responsible', 'application', 'development']\n",
            "Porter: ['develop', 'respons', 'applic', 'develop']\n",
            "Snowball: ['develop', 'respons', 'applic', 'develop']\n",
            "Lancaster: ['develop', 'respons', 'apply', 'develop']\n",
            "--------------------------------------------------\n",
            "Original: Experience in developing backend services is required\n",
            "Tokens: ['experience', 'developing', 'backend', 'services', 'required']\n",
            "Porter: ['experi', 'develop', 'backend', 'servic', 'requir']\n",
            "Snowball: ['experi', 'develop', 'backend', 'servic', 'requir']\n",
            "Lancaster: ['expery', 'develop', 'backend', 'serv', 'requir']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}